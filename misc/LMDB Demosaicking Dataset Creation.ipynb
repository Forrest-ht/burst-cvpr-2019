{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data_loaders'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-61389c02eb3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdata_loaders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'data_loaders'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import lmdb  # install lmdb by \"pip install lmdb\"\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from skimage import io, data, measure, color\n",
    "from torchvision import transforms\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import torch\n",
    "import lmdb\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "from data_loaders import *\n",
    "import pickle\n",
    "import scipy.misc\n",
    "import pandas as pd\n",
    "import utils\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "from dataset_utils import *\n",
    "% matplotlib inline\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafolder = '/home/filippos/data/MSR-Demosaicing/Dataset_LINEAR_without_noise/'\n",
    "demosaic_dataset = MSRDemosaicDataset(root_dir=datafolder+'bayer_panasonic/',\n",
    "                                      selection_file=datafolder+'bayer_panasonic/train.txt',\n",
    "                                      )\n",
    "    \n",
    "tmp_save = '/home/filippos/data/tmp/'\n",
    "files = glob.glob(tmp_save+'*.pkl')\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "datafolder = [datafolder+f for f in os.listdir(datafolder)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_translation = 10 # pixels\n",
    "max_angle = 2 # degrees\n",
    "burst_size = 8 # number of bursts\n",
    "\n",
    "for data_file in demosaic_dataset:\n",
    "    img_gt = data_file['image_gt']\n",
    "    img_input = data_file['image_input']\n",
    "    img_input_compress = np.zeros((int(img_input.shape[0]/2),int(img_input.shape[1]/2),4))\n",
    "    img_input_compress[...,0] = img_input[::2,::2,0]\n",
    "    img_input_compress[...,1] = img_input[::2,1::2,1]\n",
    "    img_input_compress[...,2] = img_input[1::2,::2,1]\n",
    "    img_input_compress[...,3] = img_input[1::2,1::2,2]\n",
    "\n",
    "    tr_x, tr_y = max_translation/img.shape[0], max_translation/img.shape[1]\n",
    "    seq = iaa.Sequential(\n",
    "        [iaa.Affine(\n",
    "                translate_percent={\"x\": (-tr_x, tr_x), \"y\": (-tr_y, tr_y)}, # translate by -max_translation to +max_translation percent (per axis)\n",
    "                rotate=(-max_angle, max_angle), # rotate by -max_angle to +max_angle degrees\n",
    "                order=3, # use bicubic\n",
    "                mode='symmetric' # use any of scikit-image's warping modes (see 2nd image from the top for examples)\n",
    "            )]\n",
    "    )\n",
    "    images_aug = seq.augment_images([img_gt]*(burst_size-1))\n",
    "    images_aug.append(img_gt)\n",
    "    images_aug = np.array(images_aug)\n",
    "\n",
    "\n",
    "    images_aug = images_aug[:,2:-2,46:-46,:]\n",
    "    img_gt = img_gt[2:-2,46:-46,:]\n",
    "    mask = np.zeros_like(images_aug)\n",
    "    mask[:,::2,::2,0] = 1\n",
    "    mask[:,::2,1::2,1] = 1\n",
    "    mask[:,1::2,::2,1] = 1\n",
    "    mask[:,1::2,1::2,2] = 1\n",
    "    images_aug *= mask\n",
    "    json_burst = {}\n",
    "    json_burst['image_gt'] = img_gt\n",
    "    json_burst['image_input'] = images_aug\n",
    "    json_burst['filename'] = data_file['filename']\n",
    "    pickle.dump(json_burst,open(tmp_save+'/'+json_burst['filename']+'.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = glob.glob(tmp_save+'*.pkl')\n",
    "\n",
    "class JSONDataset(Dataset):\n",
    "    \"\"\"JSON dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, path):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.file_list = glob.glob(path+'*.pkl')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = pickle.load(open(self.file_list[idx],'rb'))\n",
    "        try:\n",
    "            warp_matrix = calculate_affine_matrices(sample['image_input'])\n",
    "            if warp_matrix is None: return None\n",
    "            sample['warp_matrix'] = warp_matrix\n",
    "            return sample\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = JSONDataset(tmp_save)\n",
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_files(lmdb_dataset, dataset):\n",
    "    cnt = 0\n",
    "    cache = {}\n",
    "    nSamples = len(dataset)\n",
    "    for i, sample in enumerate(dataset):\n",
    "        if sample is None:\n",
    "            print('Lost One')\n",
    "            continue\n",
    "        if not np.array_equal(sample['warp_matrix'][-1],np.array([[1,0,0],[0,1,0]])):\n",
    "            print('error')\n",
    "        sample_json = json.dumps(sample, cls=NumpyEncoder)\n",
    "        jsonKey = 'json-%09d' % cnt\n",
    "        cache[jsonKey.encode()] = sample_json.encode()\n",
    "        if cnt % 30 == 0:\n",
    "            writeCache(lmdb_dataset, cache)\n",
    "            cache = {}\n",
    "            print('Written %d / %d' % (cnt, nSamples))\n",
    "        cnt += 1\n",
    "    nSamples = cnt\n",
    "    cache['num-samples'.encode()] = str(nSamples).encode()\n",
    "    writeCache(lmdb_dataset, cache)\n",
    "    print('Done!')\n",
    "    \n",
    "\n",
    "class lmdbDataset(Dataset):\n",
    "\n",
    "    def __init__(self, lmdb_path, transform=None):\n",
    "        self.env = lmdb.open(lmdb_path,\n",
    "                 max_readers=100,\n",
    "                 readonly=True,\n",
    "                 lock=False,\n",
    "                 readahead=False,\n",
    "                 meminit=False)\n",
    "        self.txn = self.env.begin(write=False) \n",
    "        self.nSamples = int(self.txn.get('num-samples'.encode()))\n",
    "        self.indices = range(self.nSamples) \n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.nSamples\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        jsonKey = 'json-%09d' % (index)\n",
    "        sample = self.txn.get(jsonKey.encode())\n",
    "        sample = json.loads(sample)\n",
    "        for k in sample.keys():\n",
    "            if type(sample[k]) is list:\n",
    "                sample[k] = np.array(sample[k])\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "def lmdb_nsamples(db):\n",
    "    env = lmdb.open(db,\n",
    "                max_readers=1,\n",
    "                readonly=True,\n",
    "                lock=False,\n",
    "                readahead=False,\n",
    "                meminit=False)\n",
    "\n",
    "    with env.begin(write=False) as txn:\n",
    "        nSamples = int(txn.get('num-samples'.encode()))\n",
    "    return nSamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written 0 / 600\n",
      "Written 30 / 600\n",
      "Written 60 / 600\n",
      "Written 90 / 600\n",
      "Written 120 / 600\n",
      "Written 150 / 600\n",
      "Written 180 / 600\n",
      "Written 210 / 600\n",
      "Written 240 / 600\n",
      "Written 270 / 600\n",
      "0 /io/opencv/modules/video/src/ecc.cpp:540: error: (-7) The algorithm stopped before its convergence. The correlation is going to be minimized. Images may be uncorrelated or non-overlapped in function findTransformECC\n",
      "\n",
      "1 /io/opencv/modules/video/src/ecc.cpp:525: error: (-7) NaN encountered. in function findTransformECC\n",
      "\n",
      "Lost One\n",
      "Written 300 / 600\n",
      "Written 330 / 600\n",
      "Written 360 / 600\n",
      "0 /io/opencv/modules/video/src/ecc.cpp:540: error: (-7) The algorithm stopped before its convergence. The correlation is going to be minimized. Images may be uncorrelated or non-overlapped in function findTransformECC\n",
      "\n",
      "1 /io/opencv/modules/video/src/ecc.cpp:540: error: (-7) The algorithm stopped before its convergence. The correlation is going to be minimized. Images may be uncorrelated or non-overlapped in function findTransformECC\n",
      "\n",
      "Lost One\n",
      "0 /io/opencv/modules/video/src/ecc.cpp:540: error: (-7) The algorithm stopped before its convergence. The correlation is going to be minimized. Images may be uncorrelated or non-overlapped in function findTransformECC\n",
      "\n",
      "Written 390 / 600\n",
      "Written 420 / 600\n",
      "Written 450 / 600\n",
      "Written 480 / 600\n",
      "0 /io/opencv/modules/video/src/ecc.cpp:540: error: (-7) The algorithm stopped before its convergence. The correlation is going to be minimized. Images may be uncorrelated or non-overlapped in function findTransformECC\n",
      "\n",
      "0 /io/opencv/modules/video/src/ecc.cpp:525: error: (-7) NaN encountered. in function findTransformECC\n",
      "\n",
      "1 /io/opencv/modules/video/src/ecc.cpp:540: error: (-7) The algorithm stopped before its convergence. The correlation is going to be minimized. Images may be uncorrelated or non-overlapped in function findTransformECC\n",
      "\n",
      "Lost One\n",
      "Written 510 / 600\n",
      "0 /io/opencv/modules/video/src/ecc.cpp:540: error: (-7) The algorithm stopped before its convergence. The correlation is going to be minimized. Images may be uncorrelated or non-overlapped in function findTransformECC\n",
      "\n",
      "1 /io/opencv/modules/video/src/ecc.cpp:540: error: (-7) The algorithm stopped before its convergence. The correlation is going to be minimized. Images may be uncorrelated or non-overlapped in function findTransformECC\n",
      "\n",
      "Lost One\n",
      "Written 540 / 600\n",
      "Written 570 / 600\n",
      "Done!\n",
      "596\n"
     ]
    }
   ],
   "source": [
    "outputPath = '/home/filippos/data/MSR_burst_train_v3_augmented.lmdb'\n",
    "if not os.path.exists(outputPath):\n",
    "    os.makedirs(outputPath)\n",
    "env = lmdb.open(outputPath, map_size=1048576000*10)\n",
    "store_files(env, ds)\n",
    "env.close()\n",
    "print(lmdb_nsamples(outputPath))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
